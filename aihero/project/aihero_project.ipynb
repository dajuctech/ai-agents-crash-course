{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09598e5d-4ca3-4e14-8915-1dff7e951d2f",
   "metadata": {},
   "source": [
    "### Day 1: Ingest and Index Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560bc522-b262-4c54-a88b-9fdecd61773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name, branch='main'):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "        branch: Branch name (default: 'main', some repos use 'master')\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/{branch}'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845ecb9a-0f86-4c36-b60d-de156cb978f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 744 documents\n",
      "Downloaded: 1227 documents\n",
      "Downloaded: 40 documents\n",
      "Downloaded: 36 documents\n"
     ]
    }
   ],
   "source": [
    "# VS Code documentation\n",
    "mcs = read_repo_data('microsoft', 'vscode-docs')\n",
    "print(f\"Downloaded: {len(mcs)} documents\")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "hgf = read_repo_data('huggingface', 'transformers')\n",
    "print(f\"Downloaded: {len(hgf)} documents\")\n",
    "\n",
    "# Python documentation\n",
    "pyth = read_repo_data('python', 'cpython')\n",
    "print(f\"Downloaded: {len(pyth)} documents\")\n",
    "\n",
    "# LangChain uses 'master' branch\n",
    "my_docs = read_repo_data('langchain-ai', 'langchain', branch='master')\n",
    "print(f\"Downloaded: {len(my_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d771874-0980-4876-9f0b-512897817d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac8c50-a5d3-490d-8f79-60b5afcf6cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
