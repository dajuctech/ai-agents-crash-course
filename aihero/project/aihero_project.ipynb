{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128a270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-frontmatter minsearch sentence-transformers pydantic-ai tqdm pandas numpy --quiet\n",
    "\n",
    "print(\"‚úÖ Packages installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9baa3576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  OpenAI API key not set\n",
      "   To use the agent features, uncomment the line above and add your key\n",
      "   or set OPENAI_API_KEY in your environment before starting Jupyter\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION: Set your OpenAI API Key\n",
    "# =============================================================================\n",
    "# Uncomment and set your API key here, or set it as an environment variable\n",
    "\n",
    "import os\n",
    "\n",
    "# Option 1: Set directly in the notebook (not recommended for production)\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-your-api-key-here'\n",
    "\n",
    "# Option 2: Check if already set in environment\n",
    "if os.environ.get('OPENAI_API_KEY'):\n",
    "    print(\"‚úÖ OpenAI API key is already set\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OpenAI API key not set\")\n",
    "    print(\"   To use the agent features, uncomment the line above and add your key\")\n",
    "    print(\"   or set OPENAI_API_KEY in your environment before starting Jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c918755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yangshun/tech-interview-handbook...\n",
      "‚úÖ Downloaded 82 documents\n",
      "üìÑ Sample: CODE_OF_CONDUCT.md\n",
      "‚úÖ Downloaded 82 documents\n",
      "üìÑ Sample: CODE_OF_CONDUCT.md\n"
     ]
    }
   ],
   "source": [
    "# Project: Tech Interview Handbook AI Agent\n",
    "# Repository: yangshun/tech-interview-handbook\n",
    "\n",
    "# =============================================================================\n",
    "# DAY 1: DATA INGESTION\n",
    "# =============================================================================\n",
    "\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                \n",
    "                # Strip repo prefix from filename\n",
    "                _, filename_repo = filename.split('/', maxsplit=1)\n",
    "                data['filename'] = filename_repo\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n",
    "\n",
    "# Download Tech Interview Handbook\n",
    "REPO_OWNER = \"yangshun\"\n",
    "REPO_NAME = \"tech-interview-handbook\"\n",
    "\n",
    "print(f\"Downloading {REPO_OWNER}/{REPO_NAME}...\")\n",
    "tech_interview_docs = read_repo_data(REPO_OWNER, REPO_NAME)\n",
    "\n",
    "print(f\"‚úÖ Downloaded {len(tech_interview_docs)} documents\")\n",
    "print(f\"üìÑ Sample: {tech_interview_docs[0]['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3795ccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 535 chunks from 82 documents\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DAY 2: CHUNKING\n",
    "# =============================================================================\n",
    "\n",
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'content': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "def chunk_documents(docs, size=2000, step=1000):\n",
    "    chunks = []\n",
    "\n",
    "    for doc in docs:\n",
    "        doc_copy = doc.copy()\n",
    "        doc_content = doc_copy.pop('content', '')\n",
    "        \n",
    "        if len(doc_content) > size:\n",
    "            doc_chunks = sliding_window(doc_content, size=size, step=step)\n",
    "            for chunk in doc_chunks:\n",
    "                chunk.update(doc_copy)\n",
    "            chunks.extend(doc_chunks)\n",
    "        else:\n",
    "            doc_copy['content'] = doc_content\n",
    "            chunks.append(doc_copy)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "tech_interview_chunks = chunk_documents(tech_interview_docs, size=2000, step=1000)\n",
    "\n",
    "print(f\"‚úÖ Created {len(tech_interview_chunks)} chunks from {len(tech_interview_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fe173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building search index...\n",
      "‚úÖ Search index built\n",
      "\n",
      "Testing search: 'How to prepare for coding interviews?'\n",
      "\n",
      "1. Coding interviews: Everything you need to prepare\n",
      "   File: apps/website/contents/coding-interview-prep.md\n",
      "   Preview: emember the questions they have practiced before.\n",
      "\n",
      "Instead, this is how to prepare for your Software...\n",
      "\n",
      "2. Coding interviews: Everything you need to prepare\n",
      "   File: apps/website/contents/coding-interview-prep.md\n",
      "   Preview: rately determine time and space complexity and optimize them.\n",
      "1. **Technical competency** - Translat...\n",
      "\n",
      "3. Coding interviews: Everything you need to prepare\n",
      "   File: apps/website/contents/coding-interview-prep.md\n",
      "   Preview:  language should be used for interviews? Generally, we want higher level languages that have many st...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DAY 3: SEARCH ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "from minsearch import Index\n",
    "\n",
    "print(\"Building search index...\")\n",
    "\n",
    "tech_index = Index(\n",
    "    text_fields=[\"content\", \"title\", \"description\", \"filename\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "tech_index.fit(tech_interview_chunks)\n",
    "\n",
    "print(\"‚úÖ Search index built\")\n",
    "\n",
    "# Test search\n",
    "test_query = \"How to prepare for coding interviews?\"\n",
    "print(f\"\\nTesting search: '{test_query}'\")\n",
    "\n",
    "results = tech_index.search(test_query, num_results=3)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {result.get('title', result['filename'])}\")\n",
    "    print(f\"   File: {result['filename']}\")\n",
    "    preview = result.get('content', '')[:100]\n",
    "    print(f\"   Preview: {preview}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef237b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  OPENAI_API_KEY not set. Please set it before using the agent:\n",
      "   import os\n",
      "   os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
      "\n",
      "============================================================\n",
      "Testing Agent\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  Skipping test - set OPENAI_API_KEY to test the agent\n",
      "Example:\n",
      "  import os\n",
      "  os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
      "  # Then re-run this cell\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DAY 4: AGENT + TOOL INTEGRATION\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, List\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "# Set up OpenAI\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  OPENAI_API_KEY not set. Please set it before using the agent:\")\n",
    "    print(\"   import os\")\n",
    "    print(\"   os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key configured\")\n",
    "\n",
    "# Define response model\n",
    "class InterviewResponse(BaseModel):\n",
    "    answer: str\n",
    "    sources: List[str]\n",
    "\n",
    "# System prompt for the agent\n",
    "system_prompt = \"\"\"You are an expert technical interviewing coach. You help software engineers \n",
    "prepare for technical interviews by providing clear, practical advice based on proven strategies.\n",
    "\n",
    "When answering questions:\n",
    "1. Be specific and actionable\n",
    "2. Use examples where helpful\n",
    "3. Cite sources from the Tech Interview Handbook when available\n",
    "4. Keep answers concise but thorough\n",
    "5. Break down complex topics into digestible parts\n",
    "\n",
    "Always base your answers on the search results provided.\"\"\"\n",
    "\n",
    "# Create the agent\n",
    "tech_agent = Agent(\n",
    "    'openai:gpt-4o-mini',\n",
    "    system_prompt=system_prompt,\n",
    "    output_type=InterviewResponse,\n",
    "    retries=2\n",
    ")\n",
    "\n",
    "# Tool: Search the Tech Interview Handbook\n",
    "@tech_agent.tool\n",
    "def search_handbook(context, query: str) -> str:\n",
    "    \"\"\"Search the Tech Interview Handbook for relevant information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant content\n",
    "        \n",
    "    Returns:\n",
    "        A formatted string containing the top search results\n",
    "    \"\"\"\n",
    "    results = tech_index.search(query, num_results=5)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the handbook.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for i, result in enumerate(results, 1):\n",
    "        title = result.get('title', result['filename'])\n",
    "        content = result.get('content', '')[:300]\n",
    "        source = result['filename']\n",
    "        \n",
    "        formatted.append(f\"[{i}] {title}\\nSource: {source}\\n{content}...\\n\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Test the agent\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Agent\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    test_question = \"What are the most important data structures for coding interviews?\"\n",
    "    print(f\"\\nQuestion: {test_question}\")\n",
    "    print(\"\\nAnswer:\")\n",
    "\n",
    "    try:\n",
    "        # Use await in async context (Jupyter)\n",
    "        import asyncio\n",
    "        result = asyncio.run(tech_agent.run(test_question))\n",
    "        print(result.data.answer)\n",
    "        print(f\"\\nüìö Sources: {', '.join(result.data.sources)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Skipping test - set OPENAI_API_KEY to test the agent\")\n",
    "    print(\"Example:\")\n",
    "    print(\"  import os\")\n",
    "    print(\"  os.environ['OPENAI_API_KEY'] = 'sk-...'\")\n",
    "    print(\"  # Then re-run this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a48f6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Evaluation System\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  Skipping evaluation tests - OPENAI_API_KEY not set\n",
      "Set your API key in the configuration cell at the top and re-run this cell\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DAY 5: LOGGING & EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Simple conversation logger\n",
    "conversation_history = []\n",
    "\n",
    "async def ask_agent_async(question: str, log: bool = True):\n",
    "    \"\"\"Ask the agent a question and optionally log the interaction.\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = await tech_agent.run(question)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        response = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"question\": question,\n",
    "            \"answer\": result.data.answer,\n",
    "            \"sources\": result.data.sources,\n",
    "            \"elapsed_time\": round(elapsed_time, 2),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        if log:\n",
    "            conversation_history.append(response)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        response = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"question\": question,\n",
    "            \"answer\": None,\n",
    "            \"sources\": [],\n",
    "            \"elapsed_time\": round(elapsed_time, 2),\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        \n",
    "        if log:\n",
    "            conversation_history.append(response)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Evaluation System\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"\\n‚ö†Ô∏è  Skipping evaluation tests - OPENAI_API_KEY not set\")\n",
    "    print(\"Set your API key in the configuration cell at the top and re-run this cell\")\n",
    "else:\n",
    "    test_questions = [\n",
    "        \"What is Big O notation?\",\n",
    "        \"How should I prepare for system design interviews?\",\n",
    "        \"What companies have the best interview processes?\"\n",
    "    ]\n",
    "\n",
    "    for q in test_questions:\n",
    "        print(f\"\\nüìù Q: {q}\")\n",
    "        response = await ask_agent_async(q)\n",
    "        \n",
    "        if response[\"status\"] == \"success\":\n",
    "            print(f\"‚úÖ A: {response['answer'][:150]}...\")\n",
    "            print(f\"‚è±Ô∏è  Time: {response['elapsed_time']}s\")\n",
    "            print(f\"üìö Sources: {len(response['sources'])} references\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response['error']}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Conversation Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total questions: {len(conversation_history)}\")\n",
    "    successful = sum(1 for r in conversation_history if r['status'] == 'success')\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {len(conversation_history) - successful}\")\n",
    "\n",
    "    if successful > 0:\n",
    "        avg_time = sum(r['elapsed_time'] for r in conversation_history if r['status'] == 'success') / successful\n",
    "        print(f\"Average response time: {avg_time:.2f}s\")\n",
    "\n",
    "# You can save the conversation history to a file\n",
    "# with open('conversation_log.json', 'w') as f:\n",
    "#     json.dump(conversation_history, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
